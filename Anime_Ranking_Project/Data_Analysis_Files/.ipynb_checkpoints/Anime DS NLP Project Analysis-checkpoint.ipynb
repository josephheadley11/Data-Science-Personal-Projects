{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ranked_anime.csv')\n",
    "df.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Title               300 non-null    object \n",
      " 1   Rank                300 non-null    int64  \n",
      " 2   Score               300 non-null    float64\n",
      " 3   Medium              300 non-null    object \n",
      " 4   Number of Episodes  300 non-null    int64  \n",
      " 5   Episode Length      300 non-null    object \n",
      " 6   Start Date          300 non-null    object \n",
      " 7   End Date            296 non-null    object \n",
      " 8   Premier Season      300 non-null    object \n",
      " 9   Source Material     300 non-null    object \n",
      " 10  Age Rating          300 non-null    object \n",
      " 11  Number of Members   300 non-null    int64  \n",
      " 12  URLS                300 non-null    object \n",
      " 13  Synopses            300 non-null    object \n",
      " 14  Genre 1             300 non-null    object \n",
      " 15  Genre 2             236 non-null    object \n",
      " 16  Genre 3             179 non-null    object \n",
      " 17  Genre 4             132 non-null    object \n",
      " 18  Genre 5             91 non-null     object \n",
      " 19  Genre 6             44 non-null     object \n",
      " 20  Genre 7             26 non-null     object \n",
      " 21  Genre 8             2 non-null      object \n",
      " 22  Total Minutes       300 non-null    int64  \n",
      " 23  Synopsis Length     300 non-null    int64  \n",
      "dtypes: float64(1), int64(5), object(18)\n",
      "memory usage: 56.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      \"In order for something to be obtained, someth...\n",
       "1      The self-proclaimed mad scientist Rintarou Oka...\n",
       "2      Gintoki, Shinpachi, and Kagura return as the f...\n",
       "3      Hunter x Hunter is set in a world where Hunter...\n",
       "4      Seeking to restore humanity’s diminishing hope...\n",
       "                             ...                        \n",
       "295    The human eye, a well-known motif in psychedel...\n",
       "296    An animated film series based on the Ao Oni ga...\n",
       "297    Pet shop owner's daughter Chika Tokorozawa spe...\n",
       "298    A surrealistic short from minimalist cartoonis...\n",
       "299    \"Yoru no Okite\" takes us to the sky (or to hel...\n",
       "Name: Synopses, Length: 300, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Synopses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal, Word Lowercasing, & Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    # Remove punctuations and capitalization with below command\n",
    "    simple_words = [word.lower() for word in text if word not in string.punctuation]\n",
    "    for num,letter in enumerate(simple_words):\n",
    "        if letter == '—':\n",
    "            simple_words[num] = ' '\n",
    "            \n",
    "    # Rejoin priorly formed list in below command to pass to following command\n",
    "    simple_words = ''.join(simple_words)\n",
    "\n",
    "    # Remove stopwords with below command\n",
    "    clean_text = [words for words in simple_words.split() if words.lower() not in stopwords.words('english')]\n",
    "#     return simple_words\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean Synopses'] = df['Synopses'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [order, something, obtained, something, equal,...\n",
       "1      [selfproclaimed, mad, scientist, rintarou, oka...\n",
       "2      [gintoki, shinpachi, kagura, return, funloving...\n",
       "3      [hunter, x, hunter, set, world, hunters, exist...\n",
       "4      [seeking, restore, humanity’s, diminishing, ho...\n",
       "                             ...                        \n",
       "295    [human, eye, wellknown, motif, psychedelic, cu...\n",
       "296    [animated, film, series, based, ao, oni, game,...\n",
       "297    [pet, shop, owners, daughter, chika, tokorozaw...\n",
       "298    [surrealistic, short, minimalist, cartoonist, ...\n",
       "299    [yoru, okite, takes, us, sky, hell, accompany,...\n",
       "Name: Clean Synopses, Length: 300, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean Synopses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['Synopses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5870\n"
     ]
    }
   ],
   "source": [
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses_bow = bow_transformer.transform([df['Synopses']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t3\n",
      "  (0, 2)\t4\n",
      "  (0, 3)\t2\n",
      "  (0, 6)\t2\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t2\n",
      "  (0, 16)\t2\n",
      "  (0, 19)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 38)\t3\n",
      "  (0, 39)\t1\n",
      "  (0, 40)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 49)\t1\n",
      "  (0, 54)\t1\n",
      "  (0, 59)\t4\n",
      "  (0, 60)\t1\n",
      "  :\t:\n",
      "  (0, 5835)\t2\n",
      "  (0, 5836)\t2\n",
      "  (0, 5837)\t1\n",
      "  (0, 5838)\t2\n",
      "  (0, 5839)\t1\n",
      "  (0, 5840)\t1\n",
      "  (0, 5841)\t1\n",
      "  (0, 5842)\t1\n",
      "  (0, 5843)\t1\n",
      "  (0, 5844)\t1\n",
      "  (0, 5845)\t3\n",
      "  (0, 5847)\t1\n",
      "  (0, 5848)\t2\n",
      "  (0, 5849)\t1\n",
      "  (0, 5850)\t1\n",
      "  (0, 5852)\t1\n",
      "  (0, 5854)\t2\n",
      "  (0, 5857)\t3\n",
      "  (0, 5860)\t1\n",
      "  (0, 5861)\t1\n",
      "  (0, 5863)\t1\n",
      "  (0, 5864)\t4\n",
      "  (0, 5865)\t1\n",
      "  (0, 5867)\t1\n",
      "  (0, 5868)\t4\n"
     ]
    }
   ],
   "source": [
    "print(synopses_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (1, 5870)\n",
      "Amount of Non-Zero occurences:  4622\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', synopses_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', synopses_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 78.74%\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * synopses_bow.nnz / (synopses_bow.shape[0] * synopses_bow.shape[1]))\n",
    "print(f'sparsity: {round(sparsity,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Synopses']\n",
    "y = df['Genre 1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x7fb5a3d99050>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Action       0.76      0.40      0.52        40\n",
      "    Adventure       0.00      0.00      0.00         2\n",
      "       Comedy       0.69      0.48      0.56        23\n",
      "     Dementia       0.56      0.71      0.63         7\n",
      "        Drama       0.17      1.00      0.29         1\n",
      "        Ecchi       0.00      0.00      0.00         0\n",
      "        Music       0.00      0.00      0.00         0\n",
      "      Mystery       0.00      0.00      0.00         0\n",
      "Psychological       0.00      0.00      0.00         0\n",
      "       Sci-Fi       0.25      1.00      0.40         1\n",
      "Slice of Life       0.33      1.00      0.50         1\n",
      "       Sports       0.00      0.00      0.00         0\n",
      "  Super Power       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.47        75\n",
      "    macro avg       0.21      0.35      0.22        75\n",
      " weighted avg       0.68      0.47      0.53        75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephheadley/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
